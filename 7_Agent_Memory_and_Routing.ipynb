{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIPzv8x1MgyD"
      },
      "source": [
        "# Agent Memory and Routing: Building a Multi-Talented Assistant\n",
        "\n",
        "This notebook represents the culmination of our work in Agentic Architecture. We are moving beyond single-purpose agents and building a single, cohesive agent that possesses two critical, human-like abilities:\n",
        "\n",
        "1.  **Memory:** The ability to remember past interactions and handle follow-up questions in a stateful conversation.\n",
        "2.  **Routing:** The ability to intelligently choose the correct tool from a diverse toolkit based on the user's request.\n",
        "\n",
        "In this lab, we will combine the state-of-the-art RAG pipeline we built in Module 1 with the tool-calling agent from Module 2. We will create a single `AgentExecutor` that is given two distinct tools:\n",
        "\n",
        "-   A **RAG Tool** (`get_knowledge_from_library`): For answering questions about specific topics (the Transformer architecture).\n",
        "-   A **Time Tool** (`get_current_time`): For answering questions about the current time.\n",
        "\n",
        "By running a sequence of different queries, we will demonstrate that the agent can:\n",
        "-   Correctly route a knowledge-based question to the RAG tool.\n",
        "-   Correctly route a time-based question to the time tool.\n",
        "-   Use its memory to answer a question about the conversation history without needing to use a tool at all.\n",
        "\n",
        "This is the core engine of a truly useful \"Auto-Support Agent\" and demonstrates the power of modern, tool-calling LLMs to act as intelligent orchestrators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8nAPoMhJ8Fa",
        "outputId": "4ba3dc37-226e-4f0d-d888-0eedc6913e85"
      },
      "outputs": [],
      "source": [
        "# First, install the necessary libraries\n",
        "!pip install langchain langchain_openai chromadb pypdf langchain-community langchain-chroma\n",
        "\n",
        "import os\n",
        "from datetime import datetime\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.agents import tool, create_openai_tools_agent, AgentExecutor\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "# Set up your OpenAI API key\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "except ImportError:\n",
        "    print(\"Not in a Colab environment, assuming API key is set.\")\n",
        "\n",
        "# --- 1. Define the Tools ---\n",
        "# Tool 1: The time tool from our previous lab\n",
        "@tool\n",
        "def get_current_time(tool_input: str = \"\") -> str:\n",
        "    \"\"\"\n",
        "    Returns the current date and time as a string.\n",
        "    Use this tool for any questions about the current time.\n",
        "    \"\"\"\n",
        "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "# Tool 2: Our RAG retriever from Module 1\n",
        "# We need to load the vector store we created in Lab 1.1\n",
        "print(\"--- Loading RAG Retriever Tool ---\")\n",
        "persist_directory = './chroma_db_rag'\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "vector_store = Chroma(persist_directory=persist_directory, embedding_function=embedding_model)\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "@tool\n",
        "def get_knowledge_from_library(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Your primary tool. Use this to find information to answer a user's question.\n",
        "    This tool searches a library of documents about the Transformer architecture\n",
        "    and attention mechanisms. Use it for any questions about these topics.\n",
        "    \"\"\"\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "    return \"\\n---\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "# Put all tools in a list\n",
        "tools = [get_current_time, get_knowledge_from_library]\n",
        "\n",
        "# --- 2. Create the Agent with Memory ---\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "# The prompt now needs a placeholder for memory\n",
        "# `MessagesPlaceholder` is a special class that handles inserting the chat history.\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant.\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "])\n",
        "\n",
        "# Define the memory\n",
        "# We'll use a window memory to keep the last K turns of the conversation.\n",
        "memory = ConversationBufferWindowMemory(\n",
        "    k=5,\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True\n",
        ")\n",
        "\n",
        "# Create the modern tool-calling agent\n",
        "agent = create_openai_tools_agent(llm, tools, prompt)\n",
        "\n",
        "# --- 3. Create the Agent Executor ---\n",
        "agent_executor = AgentExecutor(\n",
        "    agent=agent,\n",
        "    tools=tools,\n",
        "    verbose=True,\n",
        "    memory=memory # IMPORTANT: Pass the memory to the executor\n",
        ")\n",
        "\n",
        "# --- 4. Run the Agent! ---\n",
        "# First question (uses the RAG tool)\n",
        "print(\"\\n--- Query 1: RAG Tool ---\")\n",
        "response1 = agent_executor.invoke({\"input\": \"What is the core idea of the attention mechanism?\"})\n",
        "print(\"\\nFinal Answer:\", response1['output'])\n",
        "\n",
        "# Second question (uses the time tool)\n",
        "print(\"\\n--- Query 2: Time Tool ---\")\n",
        "response2 = agent_executor.invoke({\"input\": \"Thanks! By the way, what time is it?\"})\n",
        "print(\"\\nFinal Answer:\", response2['output'])\n",
        "\n",
        "# Third question (tests memory)\n",
        "print(\"\\n--- Query 3: Memory Test ---\")\n",
        "response3 = agent_executor.invoke({\"input\": \"What was the first topic I asked you about?\"})\n",
        "print(\"\\nFinal Answer:\", response3['output'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
