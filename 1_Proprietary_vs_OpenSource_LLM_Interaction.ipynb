{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGAVQHX7c-Ey"
      },
      "source": [
        "# Lab 0.1a (Code): Interacting with Proprietary APIs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8b8Arz2aL6n",
        "outputId": "1aead1e3-c3e5-40b2-bbe0-c00cdf690458"
      },
      "outputs": [],
      "source": [
        "# First, install the necessary libraries\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji_WFEy-cq2L",
        "outputId": "8b41ec3b-e2a6-4c3e-bb35-dd2828041230"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "# Make sure you have set your API keys in Colab's Secrets Manager\n",
        "# For local development, you would set these as environment variables\n",
        "try:\n",
        "    # This is how you access secrets in Google Colab\n",
        "    from google.colab import userdata\n",
        "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "except ImportError:\n",
        "    print(\"Not in a Colab environment, make sure your API keys are set as environment variables.\")\n",
        "\n",
        "# 1. Initialize the OpenAI Client\n",
        "openai_client = OpenAI()\n",
        "\n",
        "# Our standard prompt for comparison\n",
        "prompt = \"Explain the concept of 'overfitting' in machine learning to a business manager in three short bullet points.\"\n",
        "\n",
        "print(\"--- Calling OpenAI (GPT-4o) ---\")\n",
        "openai_response = openai_client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        ")\n",
        "print(openai_response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OUILA--dCal"
      },
      "source": [
        "# Lab 0.1b (Code): Interacting with an Open-Source Model via Ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the Ollama Python library\n",
        "!pip install ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlfEC_0fdHFY",
        "outputId": "6ab26960-697a-4c16-f398-01a106e3fffd"
      },
      "outputs": [],
      "source": [
        "import ollama\n",
        "\n",
        "# This code assumes you have Ollama running on your local machine\n",
        "# and have already pulled a model (e.g., `ollama run llama3`)\n",
        "# NOTE: This cell will NOT work in Colab unless you've set up a tunnel to a local Ollama server,\n",
        "# but the code itself is what's important to understand.\n",
        "\n",
        "prompt = \"Explain the concept of 'overfitting' in machine learning to a business manager in three short bullet points.\"\n",
        "\n",
        "print(\"--- Calling local Llama 3 model via Ollama ---\")\n",
        "try:\n",
        "    response = ollama.chat(\n",
        "        model='llama3',\n",
        "        messages=[{'role': 'user', 'content': prompt}]\n",
        "    )\n",
        "    print(response['message']['content'])\n",
        "except Exception as e:\n",
        "    print(\"\\nCould not connect to a local Ollama server.\")\n",
        "    print(\"This is expected in Colab. Please ensure Ollama is installed and running on your local machine to run this code successfully.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
